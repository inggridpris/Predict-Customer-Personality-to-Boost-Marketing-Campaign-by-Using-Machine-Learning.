# -*- coding: utf-8 -*-
"""Predict Customer Personality to Boost Marketing Campaign by Using Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PnXDVuXwHrRYYrNOw_MnGmn139__adOK
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

print('Numpy Version:', np.__version__)
print('Pandas Version:', pd.__version__)
print('Seaborn Version:', sns.__version__)

from matplotlib import rcParams
rcParams['figure.figsize'] = 12, 4
rcParams['lines.linewidth'] = 3
rcParams['xtick.labelsize'] = 'x-large'
rcParams['ytick.labelsize'] = 'x-large'

df= pd.read_csv('/content/drive/My Drive/Predict Customer Personality to Boost Marketing Campaign by Using Machine Learning/marketing_campaign_data.csv')

df = pd.read_csv('marketing_campaign_data.csv')

df

df.isna().sum()

df.duplicated().sum()

df.info()

df['Year_Birth'].min()

df.sample(5)

df['Conversion_rate'] = df['Response']/df['NumWebVisitsMonth']

df['Conversion_rate'].sample(5)

from datetime import datetime
sekarang=datetime.now()
df['umur']=sekarang.year-df['Year_Birth']

df['umur'].value_counts()

df['umur'].min()

df['umur'].max()

df['kategori_umur']=np.where(df['umur']<=44, 'Pemuda', np.where(df['umur']<=64, 'Dewasa','Usia Lanjut'))

df['kategori_umur']

df.sample(5)

df['Dt_Customer_date']=pd.to_datetime(df['Dt_Customer'])

df['Dt_Customer_year']=df['Dt_Customer_date'].dt.year

df.sample(5)

df.info()

nums = ['Year_Birth','Income','Recency','MntCoke','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Response','Conversion_rate','umur']
cats = ['Education','Marital_Status','kategori_umur','Kidhome','Teenhome','Dt_Customer_year','Complain']

df[nums].describe()

df_cats = df[cats].astype('category').copy()

df_cats.describe()

df.info()

for col in cats:
    print(f'''Value count kolom {col}:''')
    print(df[col].value_counts())
    print()

features = nums
plt.figure(figsize=(8, 10))
for i in range(0, len(features)):
    plt.subplot(4, 5, i+1)
    sns.boxplot(y=df[features[i]], color='green', orient='v')
    plt.tight_layout()

features = nums
plt.figure(figsize=(12, 10))
for i in range(0, len(nums)):
    plt.subplot(4, 5, i+1)
    sns.kdeplot(x=df[features[i]], color='green')
    plt.xlabel(features[i])
    plt.tight_layout()

plt.figure(figsize=(12, 10))
for i in range(0, len(cats)):
    plt.subplot(3, 3, i+1)
    sns.countplot(x = df[cats[i]], color='green', orient='v')
    plt.tight_layout()

df.corr()

plt.figure(figsize=(10, 10))
sns.heatmap(df.corr(), cmap='Blues', annot=True, fmt='.2f')

plt.figure(figsize=(20, 20))
sns.pairplot(df[nums], diag_kind='kde')

df.info()

features = cats
plt.figure(figsize=(10, 25))
for i in range(0, len(features)):
    plt.subplot(8, 1, i+1) 
    sns.countplot(x=features[i], data=df,  palette="seismic", hue="Conversion_rate")
    #plt.xlabel(features[i])
    plt.tight_layout()
plt.savefig('cats.jpeg',dpi=200)

features = nums
plt.figure(figsize=(10, 25))
for i in range(0, len(features)):
    plt.subplot(17, 1, i+1) 
    sns.countplot(x=features[i], data=df,  palette="seismic", hue="Conversion_rate")
    #plt.xlabel(features[i])
    plt.tight_layout()



"""## Data Processing"""

df.info()

df.isna().sum()

df1=df.dropna(subset=['Conversion_rate','Income'])

df1.info()

df1.isna().sum()

df1.duplicated().sum()

nums1 = ['Year_Birth','Income','Recency','MntCoke','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Response','Conversion_rate','umur']

from scipy import stats
print(f'Jumlah baris sebelum memfilter outlier: {len(df1)}')

filtered_entries = np.array([True] * len(df1))

for col in nums1:
    zscore = abs(stats.zscore(df1[col])) # hitung absolute z-scorenya
    filtered_entries = (zscore < 3) & filtered_entries # keep yang kurang dari 3 absolute z-scorenya
    
df2 = df1[filtered_entries] # filter, cuma ambil yang z-scorenya dibawah 3

print(f'Jumlah baris setelah memfilter outlier: {len(df2)}')

mapping_education={'SMA':0, 'D3':1, 'S1':2,'S2':3,'S3':4}
df2['Education']=df2['Education'].map(mapping_education)

df2.info()

mapping_kat_usia={'Pemuda':0, 'Dewasa':1, 'Usia Lanjut':2,}
df2['kategori_umur']=df2['kategori_umur'].map(mapping_kat_usia)

df2.info()

mapping_dt_year={'2012':0, '2013':1, '2014':2}
df2['Dt_Customer_year']=df2['Dt_Customer_year'].map(mapping_dt_year)

df2.info()

cats_one = ['Marital_Status']
for cats_one in ['Marital_Status']:
    onehots = pd.get_dummies(df2[cats_one], prefix=cats_one)
    df2 = df2.join(onehots)

df2.info()

df3 = df2.drop(columns=['Unnamed: 0','ID','Marital_Status','Dt_Customer','Dt_Customer_date','Dt_Customer_year','Dt_Customer','AcceptedCmp3','AcceptedCmp4','AcceptedCmp1','AcceptedCmp2','AcceptedCmp5','Z_CostContact','Z_Revenue'])

df3.info()

df3['Income']=df3['Income'].astype(int)
df3['Conversion_rate']=df3['Conversion_rate'].astype(int)
df3['Marital_Status_Bertunangan']=df3['Marital_Status_Bertunangan'].astype(int)
df3['Marital_Status_Cerai']=df3['Marital_Status_Cerai'].astype(int)
df3['Marital_Status_Duda']=df3['Marital_Status_Duda'].astype(int)
df3['Marital_Status_Janda']=df3['Marital_Status_Janda'].astype(int)
df3['Marital_Status_Lajang']=df3['Marital_Status_Lajang'].astype(int)
df3['Marital_Status_Menikah']=df3['Marital_Status_Menikah'].astype(int)

df3.info()

feats = ['Year_Birth','Education','Kidhome','Teenhome','Income','Recency','MntCoke','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Response','Conversion_rate','umur','Complain','kategori_umur','Marital_Status_Bertunangan','Marital_Status_Cerai','Marital_Status_Duda','Marital_Status_Janda','Marital_Status_Lajang','Marital_Status_Menikah']
X=df3[feats].values

from sklearn.preprocessing import StandardScaler
x_std= StandardScaler().fit_transform(X)
new_df3=pd.DataFrame(data=x_std, columns=feats)
new_df3.describe

from sklearn.cluster import KMeans
inertia=[]

for i in range(1,11):
  kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=100, n_init=10, random_state=0)
  kmeans.fit(new_df3.values)
  inertia.append(kmeans.inertia_)

plt.figure(figsize=(10,6))
plt.plot(inertia) 
plt.savefig('ELBOW.jpeg',dpi=200)

inertias = []
mapping2 = {}
K = range(1, 10)
  
for k in K:
    # Building and fitting the model
    kmeanModel = KMeans(n_clusters=k).fit(new_df3.values)
    kmeanModel.fit(new_df3.values)
  
    inertias.append(kmeanModel.inertia_)
  
    mapping2[k] = kmeanModel.inertia_

for key, val in mapping2.items():
    print(f'{key} : {val}')

from sklearn.cluster import KMeans

from yellowbrick.cluster import SilhouetteVisualizer

K = range(1, 10)

fig, ax = plt.subplots(2,2, figsize=(15,8))
for i in K:
  kmeans=KMeans(n_clusters=i, init='k-means++', max_iter=100, n_init=10, random_state=0)
  q,mod= divmod(1,2)

visualizer= SilhouetteVisualizer(kmeans, color='red', ax=ax[q-1][mod])
visualizer.fit(new_df3.values)

from sklearn.cluster import KMeans
kmeans= KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)
kmeans.fit(new_df3.values)

KMeans(algorithm='auto',copy_x=True, init='k-means++', max_iter=300, n_clusters=5, 
       n_init=10, random_state=0, tol=0.0001, verbose=0)

from sklearn.cluster import KMeans
kmeans= KMeans(n_clusters=9, init='k-means++', max_iter=300, n_init=10, random_state=0)
kmeans.fit(new_df3.values)

KMeans(algorithm='auto',copy_x=True, init='k-means++', max_iter=300, n_clusters=9, 
       n_init=10, random_state=0, tol=0.0001, verbose=0)

from sklearn.cluster import KMeans

from yellowbrick.cluster import SilhouetteVisualizer

K = range(1, 6)

fig, ax = plt.subplots(2,2, figsize=(15,8))
for i in K:
  kmeans=KMeans(n_clusters=i, init='k-means++', max_iter=100, n_init=10, random_state=0)
  q,mod= divmod(1,2)

visualizer= SilhouetteVisualizer(kmeans, color='red', ax=ax[q-1][mod])
visualizer.fit(new_df3.values)

from sklearn.cluster import KMeans

from yellowbrick.cluster import SilhouetteVisualizer

K = range(1, 3)

fig, ax = plt.subplots(2,2, figsize=(15,8))
for i in K:
  kmeans=KMeans(n_clusters=i, init='k-means++', max_iter=100, n_init=10, random_state=0)
  q,mod= divmod(1,2)

visualizer= SilhouetteVisualizer(kmeans, color='red', ax=ax[q-1][mod])
visualizer.fit(new_df3.values)

# Commented out IPython magic to ensure Python compatibility.
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

n_cluster=5
sklearn_pca=PCA(n_components=2)
Y_sklearn = sklearn_pca.fit_transform(new_df3)
kmeans= KMeans(n_clusters=n_cluster, max_iter=300, random_state=0,algorithm='auto')

# %time fitted = kmeans.fit(Y_sklearn)
prediction = kmeans.predict(Y_sklearn)
df_pred=new_df3.assign(K_Cluster = prediction)
targets = [0, 1, 2,3]
plt.figure(figsize = (10,8))
plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction ,s=50, cmap='YlGnBu')
centers2 = fitted.cluster_centers_
plt.scatter(centers2[:, 0], centers2[:, 1],c='black', s=300, alpha=0.6);

data_labeling=new_df3.assign(K_Cluster = 'cluster_labels')

cluster = []
for i, k in data_labeling.iterrows(): #iterasi setiap row
    if k['K_Cluster'] == 0:
        cluster_name = 'Potential'
    elif k['K_Cluster'] == 3:
        cluster_name = 'Loyal'
    elif k['K_Cluster'] == 1:
        cluster_name = 'Important'
    else:
        cluster_name = 'Low Value'
    cluster.append(cluster_name)
data_labeling['cluster'] = cluster

df_cluster=data_labeling.groupby(data_labeling['cluster']).mean()
df_cluster['count']=pd.value_counts(data_labeling['cluster'])
df_cluster.head()

pca=PCA(n_components=28)
pca.fit(new_df3.values)
X_reduced= pca.transform(new_df3)

x_reduceddf=pd.DataFrame(data=X_reduced, columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11','pc12','pc13','pc14','pc15','pc16','pc17','pc18','pc19','pc20','pc21','pc22','pca23','pca24','pca25','pca26','pc27','pca28'])
x_reduceddf['cluster']=5
x_reduceddf.head()

from sklearn.metrics import silhouette_score

def visualize_silhouette_layer(new_df3):
    clusters_range = range(2,10)
    results = []

    for i in clusters_range:
        km = KMeans(n_clusters=i, random_state=42)
        cluster_labels = km.fit_predict(new_df3)

        silhouette_avg = silhouette_score(new_df3, cluster_labels)
        results.append([i, silhouette_avg])

    result = pd.DataFrame(results, columns=["n_clusters", "silhouette_score"])
    pivot_km = pd.pivot_table(result, index="n_clusters", values="silhouette_score")

    plt.figure()
    sns.heatmap(pivot_km, annot=True, linewidths=1, fmt='.3f', cmap='RdYlGn')
    plt.tight_layout()
    plt.title('Silhouette Score of K-means Clustering')
    plt.show()

visualize_silhouette_layer(new_df3)

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2, random_state=0)
kmeans.fit(new_df3.values)
new_df3['cluster'] = kmeans.labels_
new_df3['cluster'] = kmeans.labels_

new_df3.tail()

sns.scatterplot(data=new_df3, x='total_amount_spent', y='Income', hue='cluster')

new_df3['total_amount_spent'] = new_df3['MntCoke'] \
                              + new_df3['MntFruits'] \
                              + new_df3['MntMeatProducts'] \
                              + new_df3['MntFishProducts'] \
                              + new_df3['MntSweetProducts'] \
                              + new_df3['MntGoldProds']

nums

num=['Year_Birth','Income','Recency','total_amount_spent','Response','Conversion_rate','umur']

new_df3[num+['cluster']].groupby('cluster')['Income','total_amount_spent'].describe()

a=new_df3[num+['cluster']].groupby('cluster')['Year_Birth','Recency'].describe()

a

b=new_df3[num+['cluster']].groupby('cluster')['Response','Conversion_rate','umur'].describe()

b

map_cluster = {
    0 : 'No Churn',
    1 : 'Churn'
}

new_df3['cluster_mapped'] = new_df3['cluster'].map(map_cluster)

new_df3[num+['cluster']].groupby('cluster')['Income','total_amount_spent'].describe()

sns.set(rc={'figure.figsize':(3,8)})
sns.countplot(x=new_df3['cluster_mapped'], palette='Blues_d')
plt.title('#Users per cluster')
plt.xticks(rotation=20)

num=['Year_Birth','Income','Recency','total_amount_spent','Response','Conversion_rate','umur']

color=['#CDFCF6','#BCCEF8','#98A8F8','#3F0071']

sns.boxenplot(x=new_df3['cluster'], y=new_df3['Income'])
plt.title('Total Income per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['Year_Birth'])
plt.title('Year Birth per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['Recency'])
plt.title('Recency per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['total_amount_spent'])
plt.title('total amount spent per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['Response'])
plt.title('Response per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['Conversion_rate'])
plt.title('Conversion_rate per Cluster')

sns.boxenplot(x=new_df3['cluster'], y=new_df3['umur'])
plt.title('umur per Cluster')

